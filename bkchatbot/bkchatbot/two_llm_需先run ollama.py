import os
import re
import sys
import logging
import tempfile
import threading
import time
from dotenv import load_dotenv
from flask import Flask, request, abort
from linebot.v3 import WebhookHandler
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.webhooks import MessageEvent, TextMessageContent, AudioMessageContent
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    ReplyMessageRequest,
    TextMessage,
)
from qdrant_client import QdrantClient
from langchain_openai import OpenAIEmbeddings
from langchain_ollama import ChatOllama  # ä½¿ç”¨ Ollama é–‹æº LLM
from langchain.schema import HumanMessage

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
logging.basicConfig(level=logging.INFO)
load_dotenv()

# è®€å–ç’°å¢ƒè®Šæ•¸
api_key = os.getenv('OPENAI_API_KEY')
qdrant_url = os.getenv('QDRANT_URL')
qdrant_api_key = os.getenv('QDRANT_API_KEY')
channel_access_token = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
channel_secret = os.getenv('LINE_CHANNEL_SECRET')

# åˆå§‹åŒ–å‘é‡æŸ¥è©¢ Embeddings
embeddings = OpenAIEmbeddings(api_key=api_key, model="text-embedding-3-small")

# åˆå§‹åŒ– QdrantClient
qdrant_client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)

# åˆå§‹åŒ–å…©å€‹ä¸åŒçš„ ChatOllama æ¨¡å‹
llm1 = ChatOllama(model="deepseek-r1:8b", temperature=0.7, num_predict=500)
llm2 = ChatOllama(model="llama3.1", temperature=0.7, num_predict=500)

# åˆå§‹åŒ– Flask æ‡‰ç”¨
app = Flask(__name__)

if channel_secret is None or channel_access_token is None:
    print('è«‹è¨­å®š LINE_CHANNEL_SECRET å’Œ LINE_CHANNEL_ACCESS_TOKEN ç’°å¢ƒè®Šæ•¸ã€‚')
    sys.exit(1)

handler = WebhookHandler(channel_secret)
configuration = Configuration(access_token=channel_access_token)

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# ç”Ÿæˆå›è¦†ï¼ˆåŒæ™‚åŸ·è¡Œå…©å€‹ LLMï¼‰
def generate_reply(user_input, user_id):
    results = {"llm1": None, "llm2": None, "time1": None, "time2": None}

    def call_llm1():
        results["llm1"], results["time1"] = openai(user_input, user_id, llm1)

    def call_llm2():
        results["llm2"], results["time2"] = openai(user_input, user_id, llm2)

    # ä½¿ç”¨ Threading ä¸¦è¡Œå‘¼å«å…©å€‹ LLM
    thread1 = threading.Thread(target=call_llm1)
    thread2 = threading.Thread(target=call_llm2)
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()

    # æ ¼å¼åŒ–å›è¦†ï¼ŒåŒ…å«æ¨¡å‹çš„ç”Ÿæˆæ™‚é–“
    reply_message = f"""\
ğŸ”¹ **ç‰ˆæœ¬1ï¼ˆDeepSeekï¼‰**
å›è¦†æ™‚é–“: {results['time1']:.2f} ç§’
{results['llm1']}

ğŸ”¹ **ç‰ˆæœ¬2ï¼ˆLlama3.1ï¼‰**
å›è¦†æ™‚é–“: {results['time2']:.2f} ç§’
{results['llm2']}
    """
    return reply_message

@handler.add(MessageEvent, message=TextMessageContent)
def message_text(event):
    user_input = event.message.text
    user_id = event.source.user_id

    reply_message = generate_reply(user_input, user_id)

    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)
        line_bot_api.reply_message_with_http_info(
            ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=reply_message)]
            )
        )

# LLM å‘¼å«å‡½æ•¸ï¼ˆåŠ å…¥åŸ·è¡Œæ™‚é–“æ¸¬é‡ï¼‰
def openai(user_message, session_id, llm_model):
    start_time = time.time()  # è¨˜éŒ„é–‹å§‹æ™‚é–“

    input_question = user_message
    query_vector = embeddings.embed_query(input_question)

    search_results = qdrant_client.search(
        collection_name="250206-PDF-3-small-final",
        query_vector=query_vector,
        limit=1
    )
    
    search_results_description = " ".join([
        f"æ‰¾åˆ°çš„ç›¸é—œæ–‡ä»¶: {doc.payload['page_content']}" 
        for doc in search_results
    ]) if search_results else "æœªæ‰¾åˆ°èˆ‡æŸ¥è©¢ç›¸é—œçš„è³‡è¨Šã€‚"
    
    print(f"å‘é‡è³‡æ–™æœå°‹çµæœï¼ˆ{llm_model.model}ï¼‰:" + search_results_description)

    prompt_text = build_prompt_text(search_results_description)
    full_prompt = f"{prompt_text}\nä½¿ç”¨è€…å•é¡Œ: {user_message}\nè«‹ä¾ç…§ä¸Šè¿°æŒ‡å¼•ï¼Œå›ç­”ï¼š"

    reply_obj = llm_model.invoke([HumanMessage(content=full_prompt)])
    
    if hasattr(reply_obj, 'content'):
        raw_reply = reply_obj.content
    else:
        raw_reply = reply_obj

    # ç§»é™¤ <think> æ¨™ç±¤å…§å®¹
    final_reply = re.sub(r'<think>.*?</think>', '', raw_reply, flags=re.DOTALL).strip()
    
    end_time = time.time()  # è¨˜éŒ„çµæŸæ™‚é–“
    execution_time = end_time - start_time  # è¨ˆç®—åŸ·è¡Œæ™‚é–“ï¼ˆç§’ï¼‰

    return final_reply, execution_time  # å›å‚³å›è¦†èˆ‡åŸ·è¡Œæ™‚é–“


# æ§‹å»ºæç¤ºæ–‡æœ¬
def build_prompt_text(search_results_description):
    step_list = """
    0. ç¢ºä¿å›ç­”çš„å…§å®¹æº–ç¢ºç„¡èª¤ï¼Œæ¢åˆ—åˆ†æ®µå¼å›ç­”ã€‚
    1. ä½œç‚ºè‡ºç£åœŸåœ°éŠ€è¡Œæ¨‚æ´»é¤Šè€æˆ¿å±‹å°ˆæ¡ˆçš„å°ˆå®¶ï¼Œåªå›ç­”ç›¸é—œå•é¡Œã€‚
    2. ä¸è™•ç†å…¶ä»–é‡‘èæ©Ÿæ§‹æˆ–éæ¨‚æ´»é¤Šè€ç›¸é—œçš„é‡‘èã€ä¿éšªæˆ–æŠ•è³‡å•é¡Œã€‚
    3. æ‰€æœ‰å›ç­”å‡ä½¿ç”¨è‡ºç£æ­£é«”ä¸­æ–‡ï¼Œä¸¦ä¸”åƒ…æä¾›åœŸåœ°éŠ€è¡Œçš„ç›¸é—œæœå‹™è³‡è¨Šã€‚
    4. è‹¥å•é¡Œæ¶‰åŠä¸æ¸…æ¥šæˆ–ä¸ç›¸é—œå…§å®¹ï¼Œå°‡å¼•å°ä½¿ç”¨è€…è¯ç¹«åœŸåœ°éŠ€è¡Œå®¢æœã€‚
    5. ç¯„ä¾‹èˆ‡èˆ‰ä¾‹ï¼Œå¿…é ˆéå¸¸æº–ç¢ºï¼Œä¸è¦æœ‰å¤šé¤˜çš„è®ŠåŒ–ï¼Œä¾ç…§è³‡æ–™æœ¬èº«å›è¦†ã€‚
    6. æä¾›çš„èˆ‰ä¾‹æˆ–ç¯„ä¾‹é™åˆ¶ç‚ºä¸€å€‹ï¼Œå¦‚éœ€æ›´å¤šä¿¡æ¯è«‹å’¨è©¢éŠ€è¡Œã€‚
    7. å°æ–¼æåˆ°å…¶ä»–éŠ€è¡Œçš„å•é¡Œï¼Œå¦‚åœ‹æ³°ä¸–è¯ã€å°æ–°ã€å¯Œé‚¦ç­‰ï¼Œä¸€å¾‹ä¸äºˆå›ç­”ã€‚
    8. åªé‡å°é—œéµæ¢æ¬¾æä¾›é‡é»æç¤ºï¼Œä¸å…¨é¢åˆ—å‡ºï¼Œå…·é«”ç´°ç¯€å»ºè­°è«®è©¢éŠ€è¡Œã€‚
    9. å¦‚æœä¸æ¸…æ¥šå•é¡Œçš„ç´°ç¯€ï¼Œä¸æº–éš¨æ„å›ç­”ï¼Œé‡æ–°ç¢ºèªä½¿ç”¨è€…æ„åœ–ã€‚
    10.è«‹å†æ¬¡ç¢ºèªå•é¡Œçš„å…·é«”å…§å®¹ï¼Œä»¥æä¾›æœ€æº–ç¢ºçš„ä¿¡æ¯ã€‚
    11.ç”¨æˆ¶å•é¡Œä¸æ˜ç¢ºæ™‚ï¼Œå¯ä»¥æç¤ºç”¨æˆ¶æ¨‚æ´»é¤Šè€è¨ˆç•«çš„ç›¸é—œå•é¡Œã€‚
    12.ç°¡æ½”å›ç­”ï¼Œæ¯æ¬¡ä¸è¶…é100å­—ï¼Œç¢ºä¿ç”¨è©æ·ºé¡¯æ˜“æ‡‚ã€‚
    13.æ‰€æœ‰å›ç­”å‡ä½¿ç”¨è‡ºç£æ­£é«”ä¸­æ–‡ã€‚
    14.é ˜éŒ¢ã€é ˜å¤šå°‘ã€æœ‰å¤šå°‘éŒ¢...ç­‰å•é¡Œï¼Œåªç”¨æœå°‹ç¯„ä¾‹çµ¦äºˆæç¤ºã€‚
    15.ç„¡ä¿éšªç†è³ æœå‹™ï¼Œç¢ºä¿å›ç­”æº–ç¢ºã€‚
    16.å°æ–¼æŠ•è³‡ã€ç†è²¡ã€åŸºé‡‘ã€è‚¡ç¥¨ã€å‚µåˆ¸ã€ETF...ç­‰ä»‹ç´¹è«®è©¢çš†ä¸åœ¨æœå‹™ç¯„åœã€‚
    17.63æ­²(å«)å³å¯ç”³è¾¦æ¨‚æ´»é¤Šè€ã€‚
    18.æ¯æ¬¡ç”Ÿæˆå›è¦†å‰æª¢æŸ¥å…§å®¹æ˜¯å¦éµç…§æŒ‡å—ã€‚
    """
    return f"{step_list}\n{search_results_description}"

if __name__ == "__main__":
    app.run()
