import os
import sys
import logging
import tempfile
from dotenv import load_dotenv
from flask import Flask, request, abort
from linebot.v3 import WebhookHandler
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.webhooks import MessageEvent, TextMessageContent, AudioMessageContent
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    MessagingApiBlob,
    ReplyMessageRequest,
    TextMessage,
)
from linebot.v3.messaging.models.show_loading_animation_request import ShowLoadingAnimationRequest
from qdrant_client import QdrantClient
from langchain_openai import OpenAIEmbeddings
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
logging.basicConfig(level=logging.INFO)
load_dotenv()

# è®€å–ç’°å¢ƒè®Šæ•¸
api_key = os.getenv('OPENAI_API_KEY')
qdrant_url = os.getenv('QDRANT_URL')
qdrant_api_key = os.getenv('QDRANT_API_KEY')
channel_access_token = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
channel_secret = os.getenv('LINE_CHANNEL_SECRET')

# åˆå§‹åŒ– Whisper æ¨¡å‹ï¼ˆç”¨æ–¼èªéŸ³è½‰æ–‡å­—ï¼‰
whisper_client = OpenAI(api_key=api_key)

# åˆå§‹åŒ– OpenAIEmbeddingsï¼ˆç”¨æ–¼å‘é‡æŸ¥è©¢ï¼‰
embeddings = OpenAIEmbeddings(
    api_key=api_key,
    model="text-embedding-3-small",
)

# åˆå§‹åŒ– QdrantClient
qdrant_client = QdrantClient(
    url=qdrant_url,
    api_key=qdrant_api_key,
)

# è¨­å®š LLaMA 3.1 Instruct æ¨¡å‹
model_name = "meta-llama/Llama-3.1-8B-Instruct"
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
)

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quantization_config,
    device_map="auto"
)

# åˆå§‹åŒ– Flask æ‡‰ç”¨
app = Flask(__name__)

if channel_secret is None or channel_access_token is None:
    print('Please specify LINE_CHANNEL_SECRET and LINE_CHANNEL_ACCESS_TOKEN as environment variables.')
    sys.exit(1)

handler = WebhookHandler(channel_secret)
configuration = Configuration(access_token=channel_access_token)

@app.route("/callback", methods=['POST'])
def callback():
    """LINE è¨Šæ¯å›æ‡‰ç«¯é»"""
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    app.logger.info(f"Request body: {body}")
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'


# ä½¿ç”¨ OpenAI Whisper é€²è¡ŒèªéŸ³è½‰æ–‡å­—
def speech_to_text(audio_path):
    try:
        with open(audio_path, "rb") as audio_file:
            transcription = whisper_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="zh"  # æŒ‡å®šèªè¨€ç‚ºä¸­æ–‡
            )
        transcript = transcription.text.strip()
        logging.info(f"Transcript: {transcript}")
        return transcript
    except Exception as e:
        logging.error(f"Error processing audio file with OpenAI Whisper: {e}")
        return None


# è™•ç†éŸ³é »æ¶ˆæ¯äº‹ä»¶
@handler.add(MessageEvent, message=AudioMessageContent)
def handle_audio_message(event):
    with ApiClient(configuration) as api_client:
        line_bot_blob_api = MessagingApiBlob(api_client)
        audio_data = line_bot_blob_api.get_message_content(
            message_id=event.message.id
        )

        with tempfile.NamedTemporaryFile(suffix='.m4a', delete=False) as temp_audio:
            temp_audio.write(audio_data)
            temp_audio_path = temp_audio.name

        transcript = speech_to_text(temp_audio_path)
        if transcript:
            # ä½¿ç”¨å¾èªéŸ³è­˜åˆ¥å¾—åˆ°çš„æ–‡å­—é€²è¡Œå›è¦†ç”Ÿæˆ
            reply_message = generate_rag_response(transcript, event.source.user_id)
        else:
            reply_message = "ç„¡æ³•è¾¨è­˜èªéŸ³å…§å®¹"

        line_bot_api = MessagingApi(api_client)
        line_bot_api.reply_message(
            ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=reply_message)],
            )
        )

        os.remove(temp_audio_path)


@handler.add(MessageEvent, message=TextMessageContent)
def message_text(event):
    """è™•ç† LINE å‚³ä¾†çš„æ–‡å­—è¨Šæ¯"""
    user_input = event.message.text
    user_id = event.source.user_id  # å–å¾—ä½¿ç”¨è€… IDï¼ˆä½œç‚º chatIdï¼‰

    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)

        # 1ï¸âƒ£ **é¡¯ç¤ºæ€è€ƒå‹•ç•«**
        try:
            show_loading_animation_request = ShowLoadingAnimationRequest(chatId=user_id)
            line_bot_api.show_loading_animation(show_loading_animation_request)
        except Exception as e:
            logging.error(f"é¡¯ç¤ºæ€è€ƒå‹•ç•«å¤±æ•—: {e}")

        # 2ï¸âƒ£ **ç”Ÿæˆå›æ‡‰**
        reply_message = generate_rag_response(user_input, user_id)

        # 3ï¸âƒ£ **å›è¦†ä½¿ç”¨è€…è¨Šæ¯**
        line_bot_api.reply_message(
            ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=reply_message)]
            )
        )


def generate_rag_response(user_input, user_id):
    """ä½¿ç”¨ RAG + LLaMA 3.1 ç”¢ç”Ÿå›æ‡‰"""
    return query_rag_llama3(user_input, user_id)


def query_rag_llama3(user_message, session_id):
    """åŸ·è¡Œå‘é‡æª¢ç´¢ + LLaMA 3.1 ç”¢ç”Ÿå›æ‡‰"""
    
    # 1ï¸âƒ£ Qdrant å‘é‡æª¢ç´¢
    query_vector = embeddings.embed_query(user_message)
    search_results = qdrant_client.search(
        collection_name="250206-PDF-3-small-final",
        query_vector=query_vector,
        limit=1
    )

    search_results_description = "\n".join([
        f"æ‰¾åˆ°çš„ç›¸é—œæ–‡ä»¶: {doc.payload['page_content']}"
        for doc in search_results]) if search_results else "æœªæ‰¾åˆ°èˆ‡æŸ¥è©¢ç›¸é—œçš„è³‡è¨Šã€‚"

    print(f"ğŸ” å‘é‡è³‡æ–™æœå°‹çµæœ: {search_results_description}")

    # 2ï¸âƒ£ **ç¬¦åˆ LLaMA 3.1 Instruct æ ¼å¼**
    prompt_text = f"""<|begin_of_text|>
<|start_header_id|>system<|end_header_id|>
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ AI åŠ©ç†ï¼Œå°ˆé–€è§£ç­”åœŸåœ°éŠ€è¡Œæ¨‚æ´»é¤Šè€æˆ¿å±‹å°ˆæ¡ˆçš„å•é¡Œã€‚
è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæä¾›æº–ç¢ºçš„å›æ‡‰:
å°ˆå®¶è§’è‰²ï¼šåƒ…å›ç­”è‡ºç£åœŸåœ°éŠ€è¡Œæ¨‚æ´»é¤Šè€æˆ¿å±‹å°ˆæ¡ˆç›¸é—œå•é¡Œï¼Œä¸è™•ç†å…¶ä»–éŠ€è¡Œæˆ–é‡‘èç”¢å“ã€‚
å›æ‡‰åŸå‰‡ï¼šå›ç­”é ˆæº–ç¢ºç„¡èª¤ï¼Œæ¢åˆ—å¼ã€æ­£é«”ä¸­æ–‡ã€ç°¡æ½”ä¸è¶…é 100 å­—ã€‚
é™åˆ¶ç¯„åœï¼š
ä¸å›ç­”ä¿éšªã€æŠ•è³‡ã€ç†è²¡ã€åŸºé‡‘ã€è‚¡ç¥¨ã€ETF ç­‰å•é¡Œã€‚
ä¸å›æ‡‰å…¶ä»–éŠ€è¡Œï¼ˆå¦‚åœ‹æ³°ä¸–è¯ã€å°æ–°ã€å¯Œé‚¦ç­‰ï¼‰ç›¸é—œå•é¡Œã€‚
è‹¥å•é¡Œä¸æ˜ç¢ºæˆ–è¶…å‡ºç¯„åœï¼Œå¼•å°è¯ç¹«åœŸåœ°éŠ€è¡Œå®¢æœã€‚
èˆ‰ä¾‹èˆ‡ç¯„ä¾‹ï¼šæä¾›çš„ç¯„ä¾‹é ˆç²¾ç¢ºï¼Œåƒ…é™ 1 å€‹ï¼Œä¾ç…§è³‡æ–™å›æ‡‰ï¼Œä¸åšè®ŠåŒ–ã€‚
è³‡è¨Šé‡é»ï¼š
åªæä¾›é—œéµæ¢æ¬¾æ‘˜è¦ï¼Œå®Œæ•´ç´°ç¯€å»ºè­°è«®è©¢éŠ€è¡Œã€‚
63 æ­²ï¼ˆå«ï¼‰å¯ç”³è¾¦æ¨‚æ´»é¤Šè€ã€‚
ã€Œé ˜éŒ¢ã€ã€ã€Œé ˜å¤šå°‘ã€ç­‰å•é¡Œåƒ…æä¾›æœå°‹ç¯„ä¾‹æç¤ºã€‚
å…§å®¹é©—è­‰ï¼šå›ç­”å‰ç¢ºèªå•é¡Œç´°ç¯€ï¼Œç¢ºä¿å›æ‡‰ç¬¦åˆæŒ‡å—ï¼Œä¸éš¨æ„æ¨æ¸¬ã€‚
<|eot_id|>

<|start_header_id|>user<|end_header_id|>
æ ¹æ“šä»¥ä¸‹è³‡è¨Šå›ç­”å•é¡Œï¼š
{search_results_description}

ä½¿ç”¨è€…å•é¡Œï¼š{user_message}
<|eot_id|>

<|start_header_id|>assistant<|end_header_id|>
"""

    # 3ï¸âƒ£ **ä½¿ç”¨ LLaMA 3.1 ç”Ÿæˆå›æ‡‰**
    inputs = tokenizer(prompt_text, return_tensors="pt", truncation=True, max_length=1024).to("cuda")

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=150,   # é™åˆ¶æœ€å¤š 150 å€‹ token
            temperature=0.3,      # é™ä½éš¨æ©Ÿæ€§ï¼Œç¢ºä¿å›ç­”ç©©å®š
            repetition_penalty=1.1,
            do_sample=False       # é—œé–‰éš¨æ©Ÿå–æ¨£ï¼Œæé«˜ä¸€è‡´æ€§
        )

    final_reply = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
    final_reply = final_reply.split("assistant", 1)[-1].strip(": \n")

    return final_reply

if __name__ == "__main__":
    app.run()
